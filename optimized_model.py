import numpy as np
import pandas as pd
import statsmodels.api as sm
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import r2_score, mean_squared_error
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st

# Cache pour √©viter de recalculer les mod√®les d√©j√† √©valu√©s
@st.cache_data
def evaluer_combinaison(X, y, features, _type="linear"):
    """√âvalue une combinaison de variables et retourne les m√©triques (mis en cache)"""
    X_subset = X[features]
    
    if _type == "poly":
        poly = PolynomialFeatures(degree=2, include_bias=False)
        X_subset = poly.fit_transform(X_subset)
        model = LinearRegression()
    else:
        model = LinearRegression()
    
    model.fit(X_subset, y)
    y_pred = model.predict(X_subset)
    
    r2 = r2_score(y, y_pred)
    rmse = np.sqrt(mean_squared_error(y, y_pred))
    cv = rmse / np.mean(y) if np.mean(y) != 0 else np.inf
    bias = np.mean(y_pred - y) / np.mean(y) if np.mean(y) != 0 else np.inf
    
    conforme = r2 > 0.75 and abs(cv) < 0.2 and abs(bias) < 0.01
    
    return {
        'r2': r2,
        'cv': cv,
        'bias': bias,
        'model': model,
        'conforme': conforme,
        'y_pred': y_pred
    }

class OptimizedModelIPMVP:
    def __init__(self):
        self.best_model = None
        self.best_features = None
        self.best_formula = None
        self.best_r2 = 0
        self.best_cv = None
        self.best_bias = None
        self.best_model_type = None
        self.best_coefficients = None
        self.best_intercept = None
        self.best_y_pred = None
    
    def trouver_meilleur_modele(self, X, y, max_features=4, progress_callback=None):
        """Version optimis√©e qui utilise le cache et prioritise les mod√®les prometteurs"""
        # Recherche rapide: commencer par v√©rifier la colonne DJU seule
        dju_colonne = None
        for col in X.columns:
            if 'dju' in str(col).lower():
                dju_colonne = col
                break
        
        if dju_colonne:
            # Tester le mod√®le DJU d'abord (le plus susceptible d'√™tre conforme)
            result = evaluer_combinaison(X, y, [dju_colonne])
            if result['conforme']:
                self._update_best_model(result, [dju_colonne], "Lin√©aire (E = a√óDJU + c)", X, y)
                # Si on trouve un mod√®le DJU conforme, terminer rapidement
                return True
        
        # Si le mod√®le DJU n'est pas conforme, tester d'autres combinaisons
        from itertools import combinations
        
        # Limiter le nombre de variables √† tester
        max_features = min(max_features, len(X.columns))
        models_tested = 0
        total_models = sum(len(list(combinations(X.columns, i))) for i in range(1, max_features + 1))
        
        # Tester les combinaisons de variables une par une
        for n_features in range(1, max_features + 1):
            feature_combos = list(combinations(X.columns, n_features))
            for i, feature_subset in enumerate(feature_combos):
                feature_subset = list(feature_subset)
                
                # Mettre √† jour la progression
                models_tested += 1
                if progress_callback:
                    progress_callback(models_tested / total_models)
                
                # √âvaluer le mod√®le lin√©aire
                result = evaluer_combinaison(X, y, feature_subset)
                if result['conforme'] and result['r2'] > self.best_r2:
                    self._update_best_model(result, feature_subset, "Lin√©aire", X, y)
                
                # √âvaluer le mod√®le polynomial (uniquement pour 1-2 variables)
                if n_features <= 2:
                    result = evaluer_combinaison(X, y, feature_subset, _type="poly")
                    if result['conforme'] and result['r2'] > self.best_r2:
                        self._update_best_model(result, feature_subset, "Polynomiale (degr√© 2)", X, y)
        
        return self.best_model is not None
    
    def _update_best_model(self, result, features, model_type, X, y):
        """Met √† jour le meilleur mod√®le avec les r√©sultats"""
        self.best_r2 = result['r2']
        self.best_cv = result['cv']
        self.best_bias = result['bias']
        self.best_model = result['model']
        self.best_model_type = model_type
        self.best_features = features
        self.best_y_pred = result['y_pred']
        
        if hasattr(self.best_model, 'coef_'):
            self.best_coefficients = self.best_model.coef_
            self.best_intercept = self.best_model.intercept_
        
        self._construire_formule()
    
    def _construire_formule(self):
        """Construit la formule du meilleur mod√®le"""
        if self.best_model is None:
            self.best_formula = "Aucun mod√®le valide trouv√©"
            return
        
        formula = f"{self.best_intercept:.4f}"
        for i, coef in enumerate(self.best_coefficients):
            feature_name = self.best_features[i]
            formula += f" + {coef:.4f} √ó ({feature_name})"
            
        self.best_formula = formula
    
    def generer_rapport(self, y_original=None):
        """G√©n√®re un rapport sur le meilleur mod√®le"""
        if self.best_model is None:
            return "‚ùå Aucun mod√®le valide n'a pu √™tre entra√Æn√©."
        
        # S'assurer qu'on peut calculer le RMSE
        if y_original is None or self.best_y_pred is None:
            rmse = "N/A"
        else:
            rmse = np.sqrt(mean_squared_error(y_original, self.best_y_pred))
        
        rapport = f"""
        ‚úÖ RAPPORT IPMVP - {self.best_model_type}
        ------------------------------------------------------------
        üìä Variables s√©lectionn√©es : {self.best_features}
        üìä √âquation du mod√®le : {self.best_formula}
        üìà R¬≤ : {self.best_r2:.4f} (seuil IPMVP > 0.75)
        üìâ RMSE : {rmse if isinstance(rmse, str) else f"{rmse:.4f}"}
        üìä CV(RMSE) : {self.best_cv:.4f} (seuil IPMVP < 0.2)
        üìä NMBE (Biais) : {self.best_bias:.8f} (seuil IPMVP < 0.01)
        
        ‚úÖ Mod√®le conforme aux crit√®res IPMVP üéØ
        """
        return rapport
    
    def visualiser_resultats(self, X, y, dates=None):
        """Cr√©e des visualisations pour le meilleur mod√®le"""
        if self.best_model is None:
            return pd.DataFrame({"Info": ["Aucun mod√®le valide trouv√©"]})
        
        # Calculer les pr√©dictions
        X_subset = X[self.best_features]
        if "Polynomiale" in self.best_model_type:
            poly = PolynomialFeatures(degree=2, include_bias=False)
            X_subset = poly.fit_transform(X_subset)
        
        y_pred = self.best_model.predict(X_subset)
        
        # Cr√©er un DataFrame pour l'analyse
        results_df = pd.DataFrame({
            'Valeur_R√©elle': y,
            'Valeur_Pr√©dite': y_pred,
            'Erreur': y - y_pred
        })
        
        # Ajouter les dates si disponibles
        if dates is not None:
            results_df['Date'] = dates
        
        # Cr√©er les visualisations
        self._creer_graphiques(results_df, dates)
        
        return results_df
    
    def _creer_graphiques(self, results_df, dates=None):
        """Cr√©e et sauvegarde les graphiques"""
        # Graphique 1: Comparaison des m√©triques
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # Valeurs r√©elles vs pr√©dites
        axes[0, 0].scatter(results_df['Valeur_R√©elle'], results_df['Valeur_Pr√©dite'], alpha=0.6)
        axes[0, 0].plot([results_df['Valeur_R√©elle'].min(), results_df['Valeur_R√©elle'].max()], 
                     [results_df['Valeur_R√©elle'].min(), results_df['Valeur_R√©elle'].max()], 'r--')
        axes[0, 0].set_title('Valeurs R√©elles vs Pr√©dites')
        axes[0, 0].set_xlabel('Valeurs R√©elles')
        axes[0, 0].set_ylabel('Valeurs Pr√©dites')
        axes[0, 0].grid(True)
        
        # Distribution des erreurs
        sns.histplot(results_df['Erreur'], kde=True, ax=axes[0, 1])
        axes[0, 1].set_title('Distribution des Erreurs')
        axes[0, 1].set_xlabel('Erreur')
        axes[0, 1].grid(True)
        
        # Erreurs vs valeurs pr√©dites
        axes[1, 0].scatter(results_df['Valeur_Pr√©dite'], results_df['Erreur'], alpha=0.6)
        axes[1, 0].axhline(y=0, color='r', linestyle='--')
        axes[1, 0].set_title('Erreurs vs Valeurs Pr√©dites')
        axes[1, 0].set_xlabel('Valeurs Pr√©dites')
        axes[1, 0].set_ylabel('Erreur')
        axes[1, 0].grid(True)
        
        # Importance des variables
        if len(self.best_features) > 0:
            coefs = pd.DataFrame({
                'Variable': self.best_features,
                'Coefficient': np.abs(self.best_coefficients)
            })
            coefs = coefs.sort_values('Coefficient', ascending=False)
            sns.barplot(x='Coefficient', y='Variable', data=coefs, ax=axes[1, 1])
            axes[1, 1].set_title('Importance des Variables')
            axes[1, 1].grid(True)
        
        plt.tight_layout()
        plt.savefig('resultats_modele_ipmvp.png')
        
        # Graphique 2: Consommation mesur√©e vs calcul√©e
        plt.figure(figsize=(15, 6))
        
        if dates is not None and 'Date' in results_df.columns:
            # Trier par date
            results_df = results_df.sort_values('Date')
            
            # Barres pour les valeurs r√©elles
            plt.bar(range(len(results_df)), results_df['Valeur_R√©elle'], color='royalblue', 
                   width=0.6, label='Conso mesur√©e')
            
            # Ligne pour les valeurs pr√©dites
            plt.plot(range(len(results_df)), results_df['Valeur_Pr√©dite'], color='orangered',
                    marker='o', linestyle='-', linewidth=2, markersize=8, label='Conso calcul√©e')
            
            # Formater l'axe des x avec les dates
            date_labels = [d.strftime('%b-%y') if hasattr(d, 'strftime') else d for d in results_df['Date']]
            plt.xticks(range(len(results_df)), date_labels, rotation=45)
        else:
            plt.bar(range(len(results_df)), results_df['Valeur_R√©elle'], color='royalblue', 
                   width=0.6, label='Conso mesur√©e')
            plt.plot(range(len(results_df)), results_df['Valeur_Pr√©dite'], color='orangered',
                    marker='o', linestyle='-', linewidth=2, markersize=8, label='Conso calcul√©e')
        
        plt.title('Comparaison Consommation Mesur√©e vs Calcul√©e')
        plt.ylabel('Consommation')
        plt.legend()
        plt.grid(True, axis='y')
        
        # Ajouter la formule d'ajustement
        plt.figtext(0.5, 0.01, f"Formule d'ajustement: {self.best_formula}", 
                   ha='center', fontsize=12, bbox={"facecolor":"white", "alpha":0.8, "pad":5})
        
        plt.tight_layout()
        plt.savefig('comparaison_consommations.png')